# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ï¼ˆæœªè¨˜å…¥ã ã¨../data/valï¼‰ä»¥ä¸‹ã®ç”»åƒã«å¯¾ã—ã¦
# ç”»åƒåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦æ¨è«–ã‚’è¡Œã„ã€
# å„ç”»åƒã®æ­£è§£ãƒ©ãƒ™ãƒ«ï¼ˆãƒ•ã‚©ãƒ«ãƒ€åï¼‰ã¨äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã‚’æ¯”è¼ƒã—ã¦çµæœã‚’å‡ºåŠ›ã—ã¾ã™ã€‚
# å­¦ç¿’æ¡ä»¶ã‚„æ’®å½±æ¡ä»¶ãŒç•°ãªã‚‹å®Ÿé¨“ã”ã¨ã«çµæœã‚’æ•´ç†ã—ã¦ä¿å­˜ã§ãã‚‹ã‚ˆã†ã€
# --experiment ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Š experiments/ ä»¥ä¸‹ã«æ—¥æ™‚ä»˜ãã®æ¨è«–åãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ã€
# ãã®ä¸­ã«config.txtã€misclassified_images/ã€2ç¨®é¡ã®csvãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚
# --experiment ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ãªã„å ´åˆã¯æ—¥æ™‚ã®ã¿ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ãªã‚Šã¾ã™ã€‚
# config.txtï¼šå®Ÿè¡Œæ™‚ã®è¨­å®šã‚„ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ¡ä»¶ã‚’è¨˜éŒ²ã—ã¾ã™ã€‚
# ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ ../experiments_train/ ä»¥ä¸‹ã®æœ€æ–°ã® resnet18.pth ã§ã™ã€‚
# misclassified_images/ ãƒ•ã‚©ãƒ«ãƒ€ï¼šèª¤åˆ†é¡ã•ã‚ŒãŸç”»åƒãŒã“ã“ã«ã‚³ãƒ”ãƒ¼ä¿å­˜ã•ã‚Œã¾ã™ã€‚
# 2ç¨®é¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼š
# - result_all.csvï¼šå…¨ã¦ã®ç”»åƒã®çµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚
# - result_wrong.csvï¼šèª¤åˆ†é¡ã•ã‚ŒãŸç”»åƒã®ã¿ã®çµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚

import torch
from torchvision import models, transforms
from PIL import Image
import os
import sys
import argparse
import csv
from datetime import datetime
import shutil
from pathlib import Path
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import torch.nn.functional as F # ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’Softmaxã§ã‚¹ã‚³ã‚¢ã«å¤‰æ›ã™ã‚‹ãŸã‚

# --- ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«çµ¶å¯¾ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ ---
BASE_DIR = Path(__file__).resolve().parent

# --- ãƒ‘ã‚¹è¨­å®šï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰ ---
train_dir = (BASE_DIR / "../data/train").resolve()
train_exp_dir = (BASE_DIR / "../experiments_train").resolve()

# --- ã‚¯ãƒ©ã‚¹åã‚’ train_dir ã‹ã‚‰å–å¾— ---
classes = sorted(os.listdir(train_dir))
num_classes = len(classes)

# --- æœ€æ–°ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾— ---
subdirs = [
    d for d in os.listdir(train_exp_dir)
    if os.path.isdir(os.path.join(train_exp_dir, d)) and d[:8].isdigit()
]
latest_train_dir = sorted(subdirs)[-1]
model_path = train_exp_dir / latest_train_dir / "resnet18.pth"

# --- ãƒ¢ãƒ‡ãƒ«æº–å‚™ ---
model = models.resnet18(pretrained=False)
model.fc = torch.nn.Linear(model.fc.in_features, len(classes))
model.load_state_dict(torch.load(model_path, map_location="cpu"))
model.eval()

# --- å‰å‡¦ç† ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# --- å¼•æ•°å‡¦ç† ---
parser = argparse.ArgumentParser(description="ç”»åƒåˆ†é¡ã®çµæœã‚’è¡¨ç¤ºãƒ»CSVå‡ºåŠ›ï¼ˆå…¨ä»¶ + èª¤åˆ†é¡ï¼‰")
parser.add_argument("folder", nargs="?", default="../data/val", help="æ¨è«–å¯¾è±¡ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ï¼ˆçœç•¥å¯ï¼‰")
parser.add_argument("--expname", help="æ¤œè¨¼å®Ÿé¨“åã‚’æŒ‡å®š. experiments/ ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€åï¼ˆæ¥å°¾è¾ï¼‰ã«ã‚‚ãªã‚‹ï¼ˆä¾‹: --expname imageCount_100ï¼‰")
args = parser.parse_args()
# --- args.folder ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›ï¼ˆå¼•æ•°ã§æŒ‡å®šã•ã‚Œã¦ã‚‚ã€ã•ã‚Œãªãã¦ã‚‚ï¼‰ ---
args.folder = (BASE_DIR / args.folder).resolve()

# --- å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ç¢ºèª ---
if not os.path.exists(args.folder) or not os.path.isdir(args.folder):
    print("âŒ æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„ã‹ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“")
    sys.exit(1)

# --- å®Ÿé¨“ãƒ•ã‚©ãƒ«ãƒ€åã®æ±ºå®š ---
timestamp = datetime.now().strftime("%Y%m%d_%H%M")
if args.expname:
    exp_name = f"{timestamp}_{args.expname}"
else:
    exp_name = timestamp

exp_dir = (BASE_DIR / "../experiments" / exp_name).resolve()
os.makedirs(exp_dir, exist_ok=True)

# --- èª¤åˆ†é¡ç”»åƒä¿å­˜ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ ---
misclassified_dir = exp_dir / "misclassified_images"
os.makedirs(misclassified_dir, exist_ok=True)

# --- æ¨è«–å‡¦ç†é–‹å§‹ ---
results = []
total = 0
correct = 0
print(f"\nğŸ“Š æ¤œè¨¼çµæœï¼ˆ{args.folder}ï¼‰:")
for root, _, files in os.walk(args.folder):
    for filename in files:
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            img_path = Path(root) / filename
            true_label = true_label = img_path.parent.name

            image = Image.open(img_path).convert("RGB")
            image = transform(image).unsqueeze(0)

            with torch.no_grad():
                outputs = model(image)
                probs = F.softmax(outputs, dim=1)
                confidence = probs.max().item()
                _, predicted = torch.max(outputs, 1)
                predicted_label = classes[predicted.item()]

            is_correct = (predicted_label == true_label)
            total += 1
            if is_correct:
                correct += 1

            if not is_correct:
                dst_path = misclassified_dir / img_path.name
                shutil.copy2(img_path, dst_path)

            results.append({
                "path": img_path,
                "true": true_label,
                "pred": predicted_label,
                "correct": is_correct,
                "confidence": round(confidence, 3)  # å°æ•°ç¬¬3ä½ã¾ã§ã«ä¸¸ã‚ã¦è¦‹ã‚„ã™ã
            })


# --- æ··åŒè¡Œåˆ—ã‚’ä½œæˆãƒ»ä¿å­˜ ---
true_labels = [r["true"] for r in results]
pred_labels = [r["pred"] for r in results]

if true_labels and pred_labels:
    cm = confusion_matrix(true_labels, pred_labels, labels=classes)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)

    fig, ax = plt.subplots(figsize=(8, 6))
    disp.plot(ax=ax, cmap="Blues", colorbar=False, xticks_rotation=45)
    plt.title("Confusion Matrix")
    plt.tight_layout()

    # ä¿å­˜
    confusion_path = os.path.join(exp_dir, "confusion_matrix.png")
    plt.savefig(confusion_path)
    print(f"ğŸ–¼ï¸ æ··åŒè¡Œåˆ—ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {confusion_path}")

    # è¡¨ç¤º
    # plt.show()
else:
    print("âš ï¸ æ··åŒè¡Œåˆ—ã®ä½œæˆã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")


# --- è¡¨ç¤º ---
for r in results:
    mark = "âœ…" if r["correct"] else "âŒ"
    print(f"{mark} {Path(r['path']).as_posix()} | æ­£è§£: {r['true']} | äºˆæ¸¬: {r['pred']} | ç¢ºä¿¡åº¦: {r['confidence']:.3f}")

# --- çµ±è¨ˆ ---
accuracy = 100 * correct / total if total else 0
print(f"\nğŸ¯ æ­£è§£æ•°: {correct}/{total} (æ­£è§£ç‡: {accuracy:.2f}%)")

# --- config.txt ã‚’ä¿å­˜ ---
config_path = os.path.join(exp_dir, "config.txt")
with open(config_path, "w", encoding="utf-8") as cfg:
    if args.expname:
        cfg.write(f"æ¤œè¨¼å®Ÿé¨“å: {exp_name}\n")
    else:
        cfg.write(f"æ¤œè¨¼å®Ÿé¨“å: {exp_name}ï¼ˆè‡ªå‹•å‘½åï¼‰\n")
    cfg.write(f"æ—¥æ™‚: {timestamp}\n")
    cfg.write(f"æ­£è§£æ•°: {correct}/{total} (æ­£è§£ç‡: {accuracy:.2f}%)\n")
    cfg.write(f"æ¤œè¨¼å¯¾è±¡: {args.folder}\n")
    cfg.write("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\n")
    cfg.write(" - result_all.csvï¼ˆå…¨ä»¶ï¼‰\n")
    cfg.write(" - result_wrong.csvï¼ˆèª¤åˆ†é¡ï¼‰\n")
    cfg.write(f"å…¨ã‚¯ãƒ©ã‚¹æ•°: {num_classes}\n")
    cfg.write("ä½¿ç”¨ã‚¯ãƒ©ã‚¹(æ¤œè¨¼ç”»åƒæšæ•°):\n")
    total_predict_images = 0
    for cls in classes:
        predict_path = os.path.join(args.folder, cls)
        predict_count = len([
            f for f in os.listdir(predict_path)
            if os.path.isfile(os.path.join(predict_path, f)) and f.lower().endswith((".jpg", ".jpeg", ".png"))
        ]) if os.path.exists(predict_path) else 0
        total_predict_images += predict_count
        cfg.write(f" - {cls} ({predict_count})\n")
    cfg.write(f"å…¨æ¨è«–ç”»åƒæ•°: {total_predict_images} æš\n")

    shooting_path = (BASE_DIR / "../config/shooting.txt").resolve()
    if os.path.exists(shooting_path):
        cfg.write("\næ’®å½±æ¡ä»¶:\n")
        with open(shooting_path, "r", encoding="utf-8") as shoot:
            for line in shoot:
                cfg.write(f" - {line.strip()}\n")
    else:
        cfg.write("\næ’®å½±æ¡ä»¶: shooting.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n")

    # --- ä½¿ç”¨ãƒ¢ãƒ‡ãƒ« ---
    train_config_path = os.path.join(train_exp_dir, latest_train_dir, "train_config.txt")
    if os.path.exists(train_config_path):
        cfg.write("\nä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°:\n")
        with open(train_config_path, "r", encoding="utf-8") as tcf:
            for line in tcf:
                cfg.write(f" - {line.strip()}\n")
    else:
        cfg.write("\nä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°: train_config.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n")

# --- CSVï¼ˆå…¨ä»¶ï¼‰ä¿å­˜ ---
output_all = exp_dir / "result_all.csv"
with open(output_all, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["path", "true", "pred", "correct", "confidence"])
    writer.writeheader()
    for r in results:
        writer.writerow(r)

# --- CSVï¼ˆèª¤åˆ†é¡ã®ã¿ï¼‰ä¿å­˜ ---
output_wrong = exp_dir / "result_wrong.csv"
with open(output_wrong, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["path", "true", "pred", "correct", "confidence"])
    writer.writeheader()
    for r in results:
        if not r["correct"]:
            writer.writerow(r)

print(f"ğŸ“ CSVå‡ºåŠ›å®Œäº†: {output_all}, {output_wrong}")
