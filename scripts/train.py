# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€data/train ãŠã‚ˆã³ data/val ã‚’ä½¿ã£ã¦ ResNet18 ã‚’å­¦ç¿’ã—ã€
# ../experiments_train/ä»¥ä¸‹ã«æ—¥æ™‚ä»˜ãã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨è¨­å®šæƒ…å ±ï¼ˆtrain_config.txtã€train_images.txtï¼‰ã‚’ä¿å­˜ã—ã¾ã™ã€‚

import torch
import torchvision.transforms as transforms
from torchvision import datasets, models
from torch import nn, optim
from pathlib import Path
from datetime import datetime
import random
import numpy as np
import argparse

# --- BASE_DIR ã‚’ scripts/ ã«è¨­å®š ---
BASE_DIR = Path(__file__).resolve().parent

# --- å¼•æ•°å‡¦ç† ---
parser = argparse.ArgumentParser(description="ResNet18 ã®å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
parser.add_argument("--seed", type=int, help="ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’æŒ‡å®šï¼ˆä¾‹: --seed 42ï¼‰")
parser.add_argument("--expname", help="å­¦ç¿’å®Ÿé¨“åï¼ˆä¾‹: bright_800luxï¼‰")
args = parser.parse_args()

# --- ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã®è¨­å®šï¼ˆå›ºå®š or ãƒ©ãƒ³ãƒ€ãƒ ï¼‰ ---
if args.seed is not None:
    print(f"ğŸ”’ ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’ {args.seed} ã«å›ºå®šã—ã¾ã™")
else:
    args.seed = random.randint(0, 999999)
    print(f"ğŸ”„ ã‚·ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ ã« {args.seed} ã‚’ä½¿ç”¨ã—ã¾ã™")
random.seed(args.seed)
np.random.seed(args.seed)
torch.manual_seed(args.seed)
torch.cuda.manual_seed(args.seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# --- ãƒ‘ã‚¹è¨­å®š ---
train_dir = (BASE_DIR / "../data/train").resolve()
val_dir = (BASE_DIR / "../data/val").resolve()

# --- å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ ---
timestamp = datetime.now().strftime("%Y%m%d_%H%M")
if args.expname:
    exp_dir = (BASE_DIR / f"../experiments_train/{timestamp}_{args.expname}").resolve()
else:
    exp_dir = (BASE_DIR / f"../experiments_train/{timestamp}").resolve()
exp_dir.mkdir(parents=True, exist_ok=True)

model_output_path = exp_dir / "resnet18.pth"
config_path = exp_dir / "train_config.txt"
images_list_path = exp_dir / "train_images.txt"

# --- ã‚¯ãƒ©ã‚¹æ•°ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã§è‡ªå‹•å–å¾—ï¼‰ ---
classes = sorted([d.name for d in train_dir.iterdir() if d.is_dir()])
num_classes = len(classes)

# --- å‰å‡¦ç† ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# --- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ ---
train_dataset = datasets.ImageFolder(str(train_dir), transform=transform)
val_dataset = datasets.ImageFolder(str(val_dir), transform=transform)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8)

# --- ãƒ‡ãƒã‚¤ã‚¹è¨­å®š ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆResNet18ï¼‰ ---
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

# --- æå¤±é–¢æ•°ã¨æœ€é©åŒ– ---
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
num_epochs = 10

# --- å­¦ç¿’ãƒ«ãƒ¼ãƒ— ---
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç²¾åº¦
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    val_accuracy = 100 * correct / total
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%")

# --- ãƒ¢ãƒ‡ãƒ«ä¿å­˜ ---
torch.save(model.state_dict(), model_output_path)
print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_output_path}")

# --- train_config.txt ã«è¨­å®šã‚’è¨˜éŒ² ---
with config_path.open("w", encoding="utf-8") as cfg:
    cfg.write(f"æ—¥æ™‚: {timestamp}\n")
    if args.expname:
        cfg.write(f"ãƒ¢ãƒ‡ãƒ«å: {args.expname}\n")
    cfg.write(f"å…¨ã‚¯ãƒ©ã‚¹æ•°: {num_classes}\n")
    cfg.write(f"ã‚¨ãƒãƒƒã‚¯æ•°: {num_epochs}\n")
    cfg.write(f"æœ€é©åŒ–æ‰‹æ³•: Adam (lr=0.001)\n")
    cfg.write(f"æå¤±é–¢æ•°: CrossEntropyLoss\n")
    cfg.write(f"ã‚·ãƒ¼ãƒ‰: {args.seed}\n")
    cfg.write("ä½¿ç”¨ã‚¯ãƒ©ã‚¹ï¼ˆå­¦ç¿’ç”»åƒæšæ•°ï¼‰:\n")

    total_images = 0
    for cls in classes:
        cls_dir = train_dir / cls
        count = len([f for f in cls_dir.iterdir() if f.is_file() and f.suffix.lower() in [".jpg", ".jpeg", ".png"]])
        cfg.write(f" - {cls}ï¼ˆ{count}ï¼‰\n")
        total_images += count
    cfg.write(f"å…¨ç”»åƒæ•°: {total_images}\n")

# --- train_images.txt ã«ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å‡ºåŠ› ---
with images_list_path.open("w", encoding="utf-8") as f:
    for cls in classes:
        cls_dir = train_dir / cls
        for img in sorted(cls_dir.iterdir()):
            if img.is_file() and img.suffix.lower() in [".jpg", ".jpeg", ".png"]:
                f.write(str(img.resolve()) + "\n")
