# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€data/train ãŠã‚ˆã³ data/val ã‚’ä½¿ã£ã¦ ResNet18 ã‚’å­¦ç¿’ã—ã€
# ../experiments_train/ä»¥ä¸‹ã«æ—¥æ™‚ä»˜ãã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨è¨­å®šæƒ…å ±ï¼ˆtrain_config.txtï¼‰ã‚’ä¿å­˜ã—ã¾ã™ã€‚

import torch
import torchvision.transforms as transforms
from torchvision import datasets, models
from torch import nn, optim
import os
from datetime import datetime
import random
import numpy as np
import argparse

# --- å¼•æ•°å‡¦ç† ---
parser = argparse.ArgumentParser(description="ResNet18 ã®å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
parser.add_argument("--seed", type=int, help="ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’æŒ‡å®šï¼ˆä¾‹: --seed 42ï¼‰")
args = parser.parse_args()

# --- ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã®è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ ---
if args.seed is not None:
    print(f"ğŸ”’ ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’ {args.seed} ã«å›ºå®šã—ã¾ã™")
else :
    args.seed = random.randint(0, 999999)
    print(f"ğŸ”„ ã‚·ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ ã« {args.seed} ã‚’ä½¿ç”¨ã—ã¾ã™")
random.seed(args.seed)
np.random.seed(args.seed)
torch.manual_seed(args.seed)
torch.cuda.manual_seed(args.seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# --- ãƒ‘ã‚¹è¨­å®š ---
train_dir = "../data/train"
val_dir = "../data/val"

# --- å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ ---
timestamp = datetime.now().strftime("%Y%m%d_%H%M")
exp_dir = os.path.join("../experiments_train", timestamp)
os.makedirs(exp_dir, exist_ok=True)
model_output_path = os.path.join(exp_dir, "resnet18.pth")

# --- ã‚¯ãƒ©ã‚¹æ•°ï¼ˆè‡ªå‹•å–å¾—ï¼‰ ---
classes = sorted(os.listdir(train_dir))
num_classes = len(classes)

# --- å‰å‡¦ç† ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# --- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ ---
train_dataset = datasets.ImageFolder(train_dir, transform=transform)
val_dataset = datasets.ImageFolder(val_dir, transform=transform)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8)

# --- ãƒ‡ãƒã‚¤ã‚¹è¨­å®š ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆResNet18ï¼‰ ---
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

# --- æå¤±é–¢æ•°ã¨æœ€é©åŒ– ---
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
num_epochs = 10

# --- å­¦ç¿’ãƒ«ãƒ¼ãƒ— ---
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç²¾åº¦
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    val_accuracy = 100 * correct / total
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%")

# --- ãƒ¢ãƒ‡ãƒ«ä¿å­˜ ---
torch.save(model.state_dict(), model_output_path)
print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_output_path}")

# --- train_images.txt ã«å­¦ç¿’ç”»åƒã®ãƒ‘ã‚¹ã‚’è¨˜éŒ² ---
image_list_path = os.path.join(exp_dir, "train_images.txt")
with open(image_list_path, "w", encoding="utf-8") as imglist:
    for cls in classes:
        cls_dir = os.path.join(train_dir, cls)
        image_files = sorted([
            f for f in os.listdir(cls_dir)
            if os.path.isfile(os.path.join(cls_dir, f)) and f.lower().endswith((".jpg", ".jpeg", ".png"))
        ])
        for f in image_files:
            # ç›¸å¯¾ãƒ‘ã‚¹ã¨ã—ã¦è¨˜éŒ²ï¼ˆä¾‹: clip/S__12345.jpgï¼‰
            imglist.write(f"{cls}/{f}\n")


# --- train_config.txt ã«è¨­å®šã‚’è¨˜éŒ² ---
config_path = os.path.join(exp_dir, "train_config.txt")
with open(config_path, "w", encoding="utf-8") as cfg:
    cfg.write(f"æ—¥æ™‚: {timestamp}\n")
    cfg.write(f"ã‚¨ãƒãƒƒã‚¯æ•°: {num_epochs}\n")
    cfg.write(f"æœ€é©åŒ–æ‰‹æ³•: Adam (lr=0.001)\n")
    cfg.write(f"æå¤±é–¢æ•°: CrossEntropyLoss\n")
    cfg.write(f"ã‚·ãƒ¼ãƒ‰: {args.seed}\n")
    cfg.write(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§: train_images.txt ã«è¨˜éŒ²æ¸ˆã¿\n")
    cfg.write("ä½¿ç”¨ã‚¯ãƒ©ã‚¹ï¼ˆå­¦ç¿’ç”»åƒæšæ•°ï¼‰:\n")
    for cls in classes:
        cls_dir = os.path.join(train_dir, cls)
        count = len([
            f for f in os.listdir(cls_dir)
            if os.path.isfile(os.path.join(cls_dir, f)) and f.lower().endswith((".jpg", ".jpeg", ".png"))
        ])
        cfg.write(f" - {cls}ï¼ˆ{count}ï¼‰\n")
